{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for data processing\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Imports for ML models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Imports for evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Other imports\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Ensure reproducibility\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and perform train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>144.90</td>\n",
       "      <td>26.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>Rural</td>\n",
       "      <td>106.22</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>79.95</td>\n",
       "      <td>25.9</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>96.57</td>\n",
       "      <td>34.1</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>Rural</td>\n",
       "      <td>69.84</td>\n",
       "      <td>13.7</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>Female</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>232.89</td>\n",
       "      <td>34.0</td>\n",
       "      <td>smokes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>Male</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>191.61</td>\n",
       "      <td>37.5</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>Male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.43</td>\n",
       "      <td>39.1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.00</td>\n",
       "      <td>32.7</td>\n",
       "      <td>smokes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>Female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>57.40</td>\n",
       "      <td>22.9</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4088 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0       Male  82.0             0              1          Yes        Private   \n",
       "1       Male   4.0             0              0           No       children   \n",
       "2       Male  58.0             0              0          Yes        Private   \n",
       "3     Female  20.0             0              0           No        Private   \n",
       "4     Female  10.0             0              0           No       children   \n",
       "...      ...   ...           ...            ...          ...            ...   \n",
       "4083  Female  51.0             0              0          Yes  Self-employed   \n",
       "4084    Male  64.0             0              1          Yes        Private   \n",
       "4085    Male  37.0             0              0          Yes  Self-employed   \n",
       "4086  Female  22.0             0              0           No        Private   \n",
       "4087  Female  19.0             0              0           No        Private   \n",
       "\n",
       "     Residence_type  avg_glucose_level   bmi smoking_status  stroke  \n",
       "0             Urban             144.90  26.4         smokes       1  \n",
       "1             Rural             106.22  16.7        Unknown       0  \n",
       "2             Urban              79.95  25.9   never smoked       0  \n",
       "3             Rural              96.57  34.1   never smoked       0  \n",
       "4             Rural              69.84  13.7        Unknown       0  \n",
       "...             ...                ...   ...            ...     ...  \n",
       "4083          Urban             232.89  34.0         smokes       0  \n",
       "4084          Urban             191.61  37.5         smokes       1  \n",
       "4085          Rural              82.43  39.1        Unknown       0  \n",
       "4086          Rural              62.00  32.7         smokes       0  \n",
       "4087          Rural              57.40  22.9        Unknown       0  \n",
       "\n",
       "[4088 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "datapath = \"data/healthcare-dataset-stroke-data-train.csv\"\n",
    "df = pd.read_csv(datapath)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and label\n",
    "features = [col for col in list(df.columns) if col!=\"stroke\"]\n",
    "X, y = df[features], df[\"stroke\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data preprocessing steps according to the EDA performed in file `1-eda.ipynb`:\n",
    "- Impute missing values with the mean\n",
    "- Perform one hot encoding on categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EDA, however, misses one important step, which is the scaling of the data. It was not discussed in EDA because it actually makes it harder to understand the data. However, since we are using models that evaluate distances between datapoints, it is very important to scale our data.\n",
    "\n",
    "Since the models we will be using do not assume normally distributed data, all features will be normalized in the [0, 1] range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, the following steps are performed for preprocessing the data:\n",
    "- Impute missing values with mean for the numerical columns\n",
    "- One hot encoding for categorical columns\n",
    "- MinMaxNormalization for every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mean imputer and feature scaler\n",
    "num_features = [col for col in features if df[col].dtype in [\"int64\", \"float64\"]]\n",
    "imputer = SimpleImputer()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create numerical preprocessor\n",
    "num_preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", imputer),\n",
    "    (\"scaler\", scaler)\n",
    "])\n",
    "\n",
    "# Create the one-hot encoder\n",
    "handle_unknown = \"error\"\n",
    "one_hot_features = [\"work_type\", \"smoking_status\"]\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=handle_unknown)\n",
    "\n",
    "# Create ordinal encoder\n",
    "cat_features = [col for col in features if col not in num_features]\n",
    "ordinal_features = [col for col in cat_features if col not in one_hot_features]\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Create categorical preprocessor\n",
    "cat_preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"onehot\", one_hot_encoder, one_hot_features),\n",
    "    (\"ordinal\", ordinal_encoder, ordinal_features)\n",
    "])\n",
    "\n",
    "# Create the preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_preprocessor\", num_preprocessor, num_features),\n",
    "    (\"cat_preprocessor\", cat_preprocessor, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before going into the model selection phase, it is important to recall that the used dataset is imbalanced. More specifically, there are a lot fewer datapoints of patients who actually had a stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compensate for their smaller frequency, we can increase their importance by giving them more weight. The following code cell calculates the class weights for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 20.181347150259068, 0: 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_class_weights(X, y):\n",
    "    # Create the class weights due to data imbalance\n",
    "    largest_class_size = max([X[y==c].shape[0] for c in y.unique()])\n",
    "    class_weights = {c: largest_class_size/X[y==c].shape[0] for c in y.unique()}\n",
    "    return class_weights\n",
    "    \n",
    "get_class_weights(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, some models are can't handle this type of argument to produce their results. For a more uniform approach across all model, an over-sampling technique, `SMOTE`, is applied using the `imblearn` package. This technique generates new datapoints for the minority class to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset balancer\n",
    "resampler = SMOTE(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.0, 0: 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that SMOTE balances the dataset\n",
    "# NOTE: SMOTE here is applied to all data, later the data is split into training and validation, only training data should use SMOTE\n",
    "X_res, y_res = resampler.fit_resample(preprocessor.fit(X, y).transform(X), y)\n",
    "get_class_weights(X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the class weights, SMOTE does indeed balance our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform model selection, a few models were considered to solve this binary classification problem:\n",
    "- Logistic regression classifier\n",
    "- Support vector classifier\n",
    "- Random forest classifier\n",
    "\n",
    "They are all fitted to the training data according to the class weights and later evaluated on the validation dataset using the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.87it/s]\n",
      "Model: LR | Train score: 0.776 | Val score: 0.759      \n",
      "Cross-validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.24it/s]\n",
      "Model: SVM | Train score: 0.829 | Val score: 0.678             \n",
      "Cross-validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.09it/s]\n",
      "Model: RFC | Train score: 1.000 | Val score: 0.556             \n",
      "Cross-validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.32it/s]\n",
      "Model: KNN | Train score: 0.937 | Val score: 0.588             \n",
      "Cross-validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 18.58it/s]\n",
      "Model: DTC | Train score: 1.000 | Val score: 0.572             \n",
      "Cross-validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 36.24it/s]\n",
      "Model: GNB | Train score: 0.649 | Val score: 0.647             \n",
      "Cross-validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.37it/s]\n",
      "Model: XGB | Train score: 0.983 | Val score: 0.554             \n",
      "Cross-validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.25s/it]\n",
      "Model: NN | Train score: 0.826 | Val score: 0.675              \n",
      "Iterating models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:22<00:00,  2.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create model pool to select from\n",
    "model_pool = [\n",
    "    {\"name\": \"LR\", \"model\": LogisticRegression(random_state=random_state), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"SVM\", \"model\": SVC(random_state=random_state), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"RFC\", \"model\": RandomForestClassifier(random_state=random_state), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"KNN\", \"model\": KNeighborsClassifier(), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"DTC\", \"model\": DecisionTreeClassifier(random_state=random_state), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"GNB\", \"model\": GaussianNB(), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"XGB\", \"model\": XGBClassifier(), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"NN\", \"model\": MLPClassifier(random_state=random_state, max_iter=500, early_stopping=True), \"train_score\": 0, \"val_score\": 0}\n",
    "]\n",
    "\n",
    "# Define the metric function and number of kfold splits\n",
    "metric = roc_auc_score\n",
    "n_splits = 5\n",
    "\n",
    "# Create folds for cross-validation\n",
    "kf = KFold(n_splits=n_splits, random_state=random_state)\n",
    "\n",
    "# Iterate each model in the pool\n",
    "model_bar = tqdm(model_pool, total=len(model_pool), desc=\"Iterating models\", position=0, file=sys.stdout)\n",
    "for model_dict in model_bar:\n",
    "    \n",
    "    # Get dictionary values\n",
    "    name = model_dict[\"name\"]\n",
    "    model = model_dict[\"model\"]\n",
    "    \n",
    "    # Define the training pipeline using the model\n",
    "    train_pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"resampler\", resampler),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    # Iterate folds for cross-validation\n",
    "    kfold_bar = tqdm(enumerate(kf.split(X)), total=n_splits, desc=\"Cross-validating\", position=1, file=sys.stdout)\n",
    "    for fold, (train_idx, val_idx) in kfold_bar:\n",
    "        \n",
    "        # Define training and validation sets\n",
    "        X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "        y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "        \n",
    "        # Fit pipeline to training data\n",
    "        train_pipe = train_pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Get trained preprocessor and model\n",
    "        trained_preprocessor = train_pipe.get_params()[\"preprocessor\"]\n",
    "        trained_model = train_pipe.get_params()[\"model\"]\n",
    "        \n",
    "        # Save train data score\n",
    "        y_train_pred = train_pipe.predict(X_train)\n",
    "        score_train = roc_auc_score(y_train, y_train_pred)\n",
    "        model_dict[\"train_score\"] += score_train / n_splits\n",
    "        \n",
    "        # Define validation pipeline (remove SMOTE)\n",
    "        val_pipe = Pipeline(steps=[\n",
    "            (\"preprocessor\", trained_preprocessor),\n",
    "            (\"model\", trained_model)\n",
    "        ])\n",
    "        \n",
    "        # Save validation data score\n",
    "        y_val_pred = val_pipe.predict(X_val)\n",
    "        score_val = roc_auc_score(y_val, y_val_pred)\n",
    "        model_dict[\"val_score\"] += score_val / n_splits\n",
    "        \n",
    "    # Print final results\n",
    "    score_train = model_dict[\"train_score\"]\n",
    "    score_val = model_dict[\"val_score\"]\n",
    "    tqdm.write(f\"Model: {name} | Train score: {score_train:.3f} | Val score: {score_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from these trained models, the one that faired better was the Logistic Regressor. However, both the Support Vector Machine classifier and the Neural Network also performed quite well. The Neural Network is especially promising, as it is very likely that performing hyperparameter tuning will boost its performance quite significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stroke')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "826a6a4651f62caa374715dd183f0dd0a8a5069cec63f385f630eec5a7ee68f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
