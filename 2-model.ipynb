{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for data processing\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Imports for evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Imports for ML models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Imports for hyperparameter optimization\n",
    "import optuna as opt\n",
    "\n",
    "# Other imports\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Ensure reproducibility\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and perform train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "datapath = \"data/healthcare-dataset-stroke-data-train.csv\"\n",
    "df = pd.read_csv(datapath)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and label\n",
    "features = [col for col in list(df.columns) if col!=\"stroke\"]\n",
    "X, y = df[features], df[\"stroke\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data preprocessing steps according to the EDA performed in file `1-eda.ipynb`:\n",
    "- Impute missing values with the mean\n",
    "- Perform one hot encoding on categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EDA, however, misses one important step, which is the scaling of the data. It was not discussed in EDA because it actually makes it harder to understand the data. However, since we are using models that evaluate distances between datapoints, it is very important to scale our data.\n",
    "\n",
    "Since the models we will be using do not assume normally distributed data, all features will be normalized in the [0, 1] range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, the following steps are performed for preprocessing the data:\n",
    "- Impute missing values with mean for the numerical columns\n",
    "- One hot encoding for categorical columns\n",
    "- MinMaxNormalization for every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mean imputer and feature scaler\n",
    "num_features = [col for col in features if df[col].dtype in [\"int64\", \"float64\"]]\n",
    "imputer = SimpleImputer()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create numerical preprocessor\n",
    "num_preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", imputer),\n",
    "    (\"scaler\", scaler)\n",
    "])\n",
    "\n",
    "# Create the one-hot encoder\n",
    "handle_unknown = \"error\"\n",
    "one_hot_features = [\"work_type\", \"smoking_status\"]\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=handle_unknown)\n",
    "\n",
    "# Create ordinal encoder\n",
    "cat_features = [col for col in features if col not in num_features]\n",
    "ordinal_features = [col for col in cat_features if col not in one_hot_features]\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Create categorical preprocessor\n",
    "cat_preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"onehot\", one_hot_encoder, one_hot_features),\n",
    "    (\"ordinal\", ordinal_encoder, ordinal_features)\n",
    "])\n",
    "\n",
    "# Create the preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_preprocessor\", num_preprocessor, num_features),\n",
    "    (\"cat_preprocessor\", cat_preprocessor, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before going into the model selection phase, it is important to recall that the used dataset is imbalanced. More specifically, there are a lot fewer datapoints of patients who actually had a stroke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compensate for their smaller frequency, we can increase their importance by giving them more weight. The following code cell calculates the class weights for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(X, y):\n",
    "    # Create the class weights due to data imbalance\n",
    "    largest_class_size = max([X[y==c].shape[0] for c in y.unique()])\n",
    "    class_weights = {c: largest_class_size/X[y==c].shape[0] for c in y.unique()}\n",
    "    return class_weights\n",
    "    \n",
    "get_class_weights(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, some models are can't handle this type of argument to produce their results. For a more uniform approach across all model, an over-sampling technique, `SMOTE`, is applied using the `imblearn` package. This technique generates new datapoints for the minority class to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset balancer\n",
    "resampler = SMOTE(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that SMOTE balances the dataset\n",
    "# NOTE: SMOTE here is applied to all data, later the data is split into training and validation, only training data should use SMOTE\n",
    "X_res, y_res = resampler.fit_resample(preprocessor.fit(X, y).transform(X), y)\n",
    "get_class_weights(X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the class weights, SMOTE does indeed balance our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform model selection, we will use cross validation to better evaluate our models on validation data. One thing to note is that we can not use SMOTE in our validation pipeline, only for training. This is because we want to train the model to give the same importance to each class, but to evaluate it in a dataset as close to the test set as possible (imbalaced). To do this, we will write a costum cross validation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, pipe, n_splits, verbose=False):\n",
    "    # Create folds for cross-validation\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "\n",
    "    # Iterate folds for cross-validation\n",
    "    train_score, val_score = 0, 0\n",
    "    kfold_bar = enumerate(kf.split(X))\n",
    "    if verbose:\n",
    "        kfold_bar = tqdm(kfold_bar, total=n_splits, desc=\"Cross-validating\", position=1, file=sys.stdout)\n",
    "    for fold, (train_idx, val_idx) in kfold_bar:\n",
    "        \n",
    "        # Define training and validation sets\n",
    "        X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "        y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "        \n",
    "        # Fit pipeline to training data\n",
    "        pipe = pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Get trained preprocessor and model\n",
    "        preprocessor = pipe.get_params()[\"preprocessor\"]\n",
    "        model = pipe.get_params()[\"model\"]\n",
    "        \n",
    "        # Save train data score\n",
    "        y_train_pred = pipe.predict(X_train)\n",
    "        train_score += roc_auc_score(y_train, y_train_pred) / n_splits\n",
    "        \n",
    "        # Define validation pipeline (remove SMOTE)\n",
    "        val_pipe = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "        \n",
    "        # Save validation data score\n",
    "        y_val_pred = val_pipe.predict(X_val)\n",
    "        val_score += roc_auc_score(y_val, y_val_pred) / n_splits\n",
    "        \n",
    "    return train_score, val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform model selection, a few models were considered to solve this binary classification problem:\n",
    "- Logistic regression classifier\n",
    "- Support vector classifier\n",
    "- Random forest classifier\n",
    "\n",
    "They are all fitted to the training data according to the class weights and later evaluated on the validation dataset using the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model pool to select from\n",
    "model_pool = [\n",
    "    {\"name\": \"LR\", \"model\": LogisticRegression(random_state=random_state), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"SVM\", \"model\": SVC(random_state=random_state), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"RFC\", \"model\": RandomForestClassifier(random_state=random_state), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"KNN\", \"model\": KNeighborsClassifier(), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"DTC\", \"model\": DecisionTreeClassifier(random_state=random_state), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"GNB\", \"model\": GaussianNB(), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"XGB\", \"model\": XGBClassifier(), \"train_score\": 0, \"val_score\": 0},\n",
    "    {\"name\": \"NN\", \"model\": MLPClassifier(random_state=random_state, max_iter=500, early_stopping=True), \"train_score\": 0, \"val_score\": 0}\n",
    "]\n",
    "\n",
    "# Define the metric function and number of kfold splits\n",
    "metric = roc_auc_score\n",
    "n_splits = 5\n",
    "\n",
    "# Iterate each model in the pool\n",
    "model_bar = tqdm(model_pool, total=len(model_pool), desc=\"Iterating models\", position=0, file=sys.stdout)\n",
    "for model_dict in model_bar:\n",
    "    \n",
    "    # Get dictionary values\n",
    "    name, model = model_dict[\"name\"], model_dict[\"model\"]\n",
    "    \n",
    "    # Define the training pipeline using the model\n",
    "    train_pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"resampler\", resampler),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    # Cross validate\n",
    "    train_score, val_score = cross_validate(X, y, train_pipe, n_splits, True)\n",
    "    model_dict[\"train_score\"], model_dict[\"val_score\"] = train_score, val_score\n",
    "        \n",
    "    # Print final results\n",
    "    tqdm.write(f\"Model: {name} | Train score: {train_score:.3f} | Val score: {val_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from these trained models, the one that faired better was the Logistic Regressor. However, both the Support Vector Machine classifier and the Neural Network also performed quite well. The Neural Network is especially promising, as it is very likely that performing hyperparameter tuning will boost its performance quite significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what the best models are, we will try to find their best hyperparameters so that we can get them to perform the best they can. We will be tuning:\n",
    "- Logistic Regression Classifier\n",
    "- Support Vector Machine Classifier\n",
    "- Neural Networks Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do so, we will use an optimization package called `optuna`. First of all, let's define funtions to create the models and define their hyperparameter spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_model(trial):\n",
    "    solver = trial.suggest_categorical(\"solve\", [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]) # Solver hyperparameter\n",
    "    c = trial.suggest_float(\"c\", 1e-3, 1) # Hyperparameter for regularization strength\n",
    "    model = LogisticRegression(solver=solver, C=c, random_state=random_state)\n",
    "    return model\n",
    "    \n",
    "def SVM_model(trial):\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]) # Define kernel\n",
    "    c = trial.suggest_float(\"c\", 1e-3, 1) # Hyperparameter for regularization strength\n",
    "    model = SVC(C=c, kernel=kernel, probability=True, random_state=random_state)\n",
    "    return model\n",
    "\n",
    "def NN_model(trial):\n",
    "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 4) # Define number of hidden layers\n",
    "    hidden_layer_sizes = [trial.suggest_int(f\"hidden_layer_{i}\", 5, 20) for i in range(num_hidden_layers)] # Define features per hidden layer\n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, random_state=random_state, max_iter=500, early_stopping=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these functions, we can now create an objective function, which we will use to optimize the ROC AUC metric for all of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, name):\n",
    "    # Select model based on its name\n",
    "    if name == \"LR\":\n",
    "        model = LR_model(trial)\n",
    "    elif name == \"SVM\":\n",
    "        model = SVM_model(trial)\n",
    "    else:\n",
    "        model = NN_model(trial)\n",
    "        \n",
    "    # Define training pipeline on the model\n",
    "    train_pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"resampler\", resampler),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    # Perform cross validation\n",
    "    n_splits = 5\n",
    "    _, val_score = cross_validate(X, y, train_pipe, n_splits)\n",
    "    \n",
    "    return val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create our model pool and perform hyperparameter optimization for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model pool\n",
    "model_pool = [\n",
    "    {\"name\": \"LR\", \"study\": None},\n",
    "    {\"name\": \"SVM\", \"study\": None},\n",
    "    {\"name\": \"NN\", \"study\": None}\n",
    "]\n",
    "\n",
    "# Iterate each model in the pool\n",
    "model_bar = tqdm(model_pool, total=len(model_pool), desc=\"Iterating models\", position=0, file=sys.stdout)\n",
    "for model_dict in model_bar:\n",
    "    \n",
    "    # Set tqdm bar postfix to model name\n",
    "    name = model_dict[\"name\"]\n",
    "    model_bar.set_postfix(model=name)\n",
    "    \n",
    "    # Create optuna study\n",
    "    sampler = opt.samplers.TPESampler(seed=random_state)\n",
    "    study = opt.create_study(study_name=name, direction=\"maximize\", sampler=sampler)\n",
    "    \n",
    "    # Optimize\n",
    "    foo = lambda trial: objective(trial, name)\n",
    "    study.optimize(foo, n_trials=20)\n",
    "    model_dict[\"study\"] = study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DataScience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66c20332868a9aca664e5924ef91efac344eda67c73f1c04e9ba2cded2db297f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
